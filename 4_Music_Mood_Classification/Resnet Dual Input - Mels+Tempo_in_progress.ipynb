{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes melspectrogram and tempogram as inputs and uses Resnet model . The model overfitted. Train to avoid overfitting. [Work in Progress]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet \n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import skimage\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from skimage.transform import resize\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "labels = pd.read_csv('./input_label.csv')\n",
    "#class MelspecDataset(Dataset):\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, tempo_dir, transform=None):\n",
    "        self.labels = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.tempo_dir = tempo_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.labels.iloc[idx, 0]+'.png')\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        l = self.labels.iloc[idx, 1:]       \n",
    "        \n",
    "        tempo_img_name = os.path.join(self.tempo_dir, self.labels.iloc[idx, 0]+'.png')\n",
    "        tempo_image = io.imread(tempo_img_name)\n",
    "        \n",
    "        sample = {'image': image, 'label': l, 'tempo_image': tempo_image}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label, tempo_image = sample['image'], sample['label'], sample['tempo_image']\n",
    "        \n",
    "\n",
    "        # The input is a pandas Series\n",
    "        if isinstance(label, pd.core.series.Series):\n",
    "            label = label.values[0]\n",
    "            \n",
    "        label_id = [\"Happy\", \"Angry\", \"Tender\", \"Scary\", \"Sad\", \"Funny\"].index(label)\n",
    "        \n",
    "        #print (label, type(label))\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        \n",
    "        #TODO: Convert image to RGB\n",
    "        from PIL import Image\n",
    "        im = Image.fromarray(image)\n",
    "        image = np.array(im.convert('RGB'))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        #print (type(image), image.shape)\n",
    "        image = resize(image, (3, 224, 224))\n",
    "        #print(\"After resize\",type(image), image.shape)\n",
    "        \n",
    "\n",
    "        \n",
    "        # tempogram \n",
    "        im = Image.fromarray(tempo_image)\n",
    "        tempo_image = np.array(im.convert('RGB'))\n",
    "        tempo_image = tempo_image.transpose((2, 0, 1))\n",
    "        tempo_image = resize(tempo_image, (3, 224, 224))\n",
    "        \n",
    "        return torch.from_numpy(image), torch.from_numpy(tempo_image), torch.from_numpy(np.array([label_id]))\n",
    "        \n",
    "transformed_dataset = Dataset(csv_file='./input_label.csv',\n",
    "                              root_dir='./MelSpectrogram/',\n",
    "                              tempo_dir='./tempogram/',\n",
    "                              transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.2\n",
    "num_train = len(transformed_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the indices\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# params\n",
    "batch_size = 16\n",
    "num_workers = 1\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        transformed_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "        transformed_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 25\n",
    "num_classes = 6\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.dpo1 = nn.Dropout(0.5)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.dpo2 = nn.Droput(0.5)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dpo3 = nn.Dropout(0.5)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.dpo1(0.5)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.dpo2(0.5)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.dpo3(0.5)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc_inp1 = nn.Linear(512 * block.expansion, 256)  \n",
    "        \n",
    "        # 2nd input - replicate all the layers needed for the Resnet architecture\n",
    "        self.conv1_inp2 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1_inp2 = nn.BatchNorm2d(64)\n",
    "        self.relu_inp2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool_inp2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.dropout_inp2 = nn.Dropout(0.5)\n",
    "        self.layer1_inp2 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2_inp2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3_inp2 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4_inp2 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool_inp2 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc_inp2 = nn.Linear(512 * block.expansion, 256)\n",
    "        \n",
    "        self.fc_out = nn.Linear(256 + 256, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inp1 = x[0]\n",
    "        inp2 = x[1]\n",
    "        \n",
    "        x = self.conv1(inp1)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_inp1(x)\n",
    "        \n",
    "        inp2 = self.conv1(inp2)\n",
    "        inp2 = self.bn1(inp2)\n",
    "        inp2 = self.relu(inp2)\n",
    "        inp2 = self.dropout(inp2)\n",
    "        inp2 = self.maxpool(inp2)\n",
    "\n",
    "        inp2 = self.layer1(inp2)\n",
    "        inp2 = self.layer2(inp2)\n",
    "        inp2 = self.layer3(inp2)\n",
    "        inp2 = self.layer4(inp2)\n",
    "\n",
    "        inp2 = self.avgpool(inp2)\n",
    "        inp2 = inp2.view(inp2.size(0), -1)\n",
    "        \n",
    "        inp2 = self.fc_inp2(inp2)\n",
    "        \n",
    "        class_out = self.fc_out(torch.cat((x, inp2), 1))\n",
    "        return class_out\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(num_classes=6)\n",
    "model = model.to(device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [100/508], Loss: 1.5082\n",
      "Epoch [1/25], Step [200/508], Loss: 1.3345\n",
      "Epoch [1/25], Step [300/508], Loss: 1.2063\n",
      "Epoch [1/25], Step [400/508], Loss: 0.7352\n",
      "Epoch [1/25], Step [500/508], Loss: 0.9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.994578610152786 %\n",
      "[[ 92   3  59   1   9  53]\n",
      " [ 18 174  22   8   5  12]\n",
      " [ 95   7 491  34 180  64]\n",
      " [  5  13  25 241  12   5]\n",
      " [  5   1  91  32 129   0]\n",
      " [ 38   3  29   1   2  70]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Step [100/508], Loss: 1.0050\n",
      "Epoch [2/25], Step [200/508], Loss: 0.9154\n",
      "Epoch [2/25], Step [300/508], Loss: 1.3082\n",
      "Epoch [2/25], Step [400/508], Loss: 1.3678\n",
      "Epoch [2/25], Step [500/508], Loss: 1.1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.30458353868901 %\n",
      "[[102   4  82   1  11  74]\n",
      " [ 29 171  21   2   4  21]\n",
      " [ 99   8 523  39 212  69]\n",
      " [  2  17  24 261  21   3]\n",
      " [  5   1  63  13  89   0]\n",
      " [ 16   0   4   1   0  37]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Step [100/508], Loss: 1.2378\n",
      "Epoch [3/25], Step [200/508], Loss: 0.9852\n",
      "Epoch [3/25], Step [300/508], Loss: 0.9145\n",
      "Epoch [3/25], Step [400/508], Loss: 0.9194\n",
      "Epoch [3/25], Step [500/508], Loss: 1.4399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.15672745194677 %\n",
      "[[ 17   1  11   0   0  16]\n",
      " [ 19 173  18   6   2   9]\n",
      " [178  11 602  39 255 103]\n",
      " [  7  11  34 260  20   6]\n",
      " [  2   1  36  12  58   0]\n",
      " [ 30   4  16   0   2  70]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Step [100/508], Loss: 0.9037\n",
      "Epoch [4/25], Step [200/508], Loss: 0.8283\n",
      "Epoch [4/25], Step [300/508], Loss: 0.8148\n",
      "Epoch [4/25], Step [400/508], Loss: 1.1941\n",
      "Epoch [4/25], Step [500/508], Loss: 1.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 60.177427304090685 %\n",
      "[[123   5  81   2  12  82]\n",
      " [ 18 180  19  11   4  18]\n",
      " [ 91   9 527  33 204  60]\n",
      " [  3   7  26 258  23   4]\n",
      " [  5   0  51  12  93   0]\n",
      " [ 13   0  13   1   1  40]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Step [100/508], Loss: 0.7577\n",
      "Epoch [5/25], Step [200/508], Loss: 0.8144\n",
      "Epoch [5/25], Step [300/508], Loss: 0.6037\n",
      "Epoch [5/25], Step [400/508], Loss: 0.6433\n",
      "Epoch [5/25], Step [500/508], Loss: 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.551010349926074 %\n",
      "[[ 59   2  26   0   1  54]\n",
      " [ 10 162   8   5   3   9]\n",
      " [155  14 550  27 192  99]\n",
      " [  7  18  35 266  26   5]\n",
      " [  7   1  86  18 114   0]\n",
      " [ 15   4  12   1   1  37]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Step [100/508], Loss: 0.7743\n",
      "Epoch [6/25], Step [200/508], Loss: 1.0636\n",
      "Epoch [6/25], Step [300/508], Loss: 0.9157\n",
      "Epoch [6/25], Step [400/508], Loss: 0.6521\n",
      "Epoch [6/25], Step [500/508], Loss: 0.5838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 59.4381468703795 %\n",
      "[[ 61   3  23   1   2  33]\n",
      " [ 22 160   9   3   3  15]\n",
      " [124   4 549  25 201  87]\n",
      " [ 10  26  42 271  28   7]\n",
      " [  3   1  68  16 103   0]\n",
      " [ 33   7  26   1   0  62]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Step [100/508], Loss: 0.8836\n",
      "Epoch [7/25], Step [200/508], Loss: 0.8607\n",
      "Epoch [7/25], Step [300/508], Loss: 1.0104\n",
      "Epoch [7/25], Step [400/508], Loss: 1.0230\n",
      "Epoch [7/25], Step [500/508], Loss: 0.7263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 61.409561360276 %\n",
      "[[ 74   3  37   1   5  35]\n",
      " [ 14 179  15   9   3  12]\n",
      " [102   7 541  28 218  55]\n",
      " [  3   5  21 270  29   1]\n",
      " [  3   0  57   7  81   0]\n",
      " [ 57   7  46   2   1 101]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Step [100/508], Loss: 0.9924\n",
      "Epoch [8/25], Step [200/508], Loss: 0.7837\n",
      "Epoch [8/25], Step [300/508], Loss: 1.3640\n",
      "Epoch [8/25], Step [400/508], Loss: 1.0731\n",
      "Epoch [8/25], Step [500/508], Loss: 1.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 62.24741251848201 %\n",
      "[[126   4  79   1  10  59]\n",
      " [ 10 170   8   2   3   6]\n",
      " [ 62   3 458  20 158  39]\n",
      " [  6  18  40 277  23   7]\n",
      " [  5   1  95  15 139   0]\n",
      " [ 44   5  37   2   4  93]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Step [100/508], Loss: 1.0381\n",
      "Epoch [9/25], Step [200/508], Loss: 1.1413\n",
      "Epoch [9/25], Step [300/508], Loss: 0.8889\n",
      "Epoch [9/25], Step [400/508], Loss: 0.9971\n",
      "Epoch [9/25], Step [500/508], Loss: 1.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 59.635288319369145 %\n",
      "[[ 93   2  78   1  14  40]\n",
      " [  7 178  14   7   3   8]\n",
      " [ 56   5 497  28 234  31]\n",
      " [  3   6  36 277  36   3]\n",
      " [  2   0  22   2  43   0]\n",
      " [ 92  10  70   2   7 122]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Step [100/508], Loss: 0.8995\n",
      "Epoch [10/25], Step [200/508], Loss: 0.9923\n",
      "Epoch [10/25], Step [300/508], Loss: 1.0915\n",
      "Epoch [10/25], Step [400/508], Loss: 0.6806\n",
      "Epoch [10/25], Step [500/508], Loss: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 61.705273533760476 %\n",
      "[[110   4  63   1   7  59]\n",
      " [ 12 178  13   5   3   7]\n",
      " [ 93   6 491  21 178  63]\n",
      " [  1  10  23 266  14   3]\n",
      " [  6   1 103  23 135   0]\n",
      " [ 31   2  24   1   0  72]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Step [100/508], Loss: 1.0881\n",
      "Epoch [11/25], Step [200/508], Loss: 1.1510\n",
      "Epoch [11/25], Step [300/508], Loss: 0.7209\n",
      "Epoch [11/25], Step [400/508], Loss: 1.0517\n",
      "Epoch [11/25], Step [500/508], Loss: 0.8896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 60.91670773780187 %\n",
      "[[ 93   7  54   1   5  57]\n",
      " [  7 170   8   5   2   6]\n",
      " [118  14 591  29 261  74]\n",
      " [  5   7  28 277  26   4]\n",
      " [  1   0  18   2  42   0]\n",
      " [ 29   3  18   3   1  63]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Step [100/508], Loss: 0.6244\n",
      "Epoch [12/25], Step [200/508], Loss: 0.6785\n",
      "Epoch [12/25], Step [300/508], Loss: 0.8939\n",
      "Epoch [12/25], Step [400/508], Loss: 0.9069\n",
      "Epoch [12/25], Step [500/508], Loss: 0.9085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 61.113849186791526 %\n",
      "[[ 78   1  42   1   6  27]\n",
      " [  9 176   9   7   2   9]\n",
      " [ 85   7 520  38 212  45]\n",
      " [  1   7  26 260  29   0]\n",
      " [  4   1  57   5  83   0]\n",
      " [ 76   9  63   6   5 123]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Step [100/508], Loss: 0.8532\n",
      "Epoch [13/25], Step [200/508], Loss: 1.0428\n",
      "Epoch [13/25], Step [300/508], Loss: 0.5554\n",
      "Epoch [13/25], Step [400/508], Loss: 0.9179\n",
      "Epoch [13/25], Step [500/508], Loss: 0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 61.50813208477082 %\n",
      "[[ 86   2  35   2   3  38]\n",
      " [ 10 175  13  19   4   8]\n",
      " [109  11 541  43 197  58]\n",
      " [  2   6  19 236  19   3]\n",
      " [  3   1  80  16 113   0]\n",
      " [ 43   6  29   1   1  97]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Step [100/508], Loss: 0.6496\n",
      "Epoch [14/25], Step [200/508], Loss: 0.8041\n",
      "Epoch [14/25], Step [300/508], Loss: 0.7096\n",
      "Epoch [14/25], Step [400/508], Loss: 0.7082\n",
      "Epoch [14/25], Step [500/508], Loss: 0.4399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 61.113849186791526 %\n",
      "[[ 95   4  44   1   3  63]\n",
      " [ 12 178  16  13   3   6]\n",
      " [111   9 581  41 241  69]\n",
      " [  0   4  15 241   8   2]\n",
      " [  3   1  43  19  81   0]\n",
      " [ 32   5  18   2   1  64]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Step [100/508], Loss: 1.0922\n",
      "Epoch [15/25], Step [200/508], Loss: 0.7232\n",
      "Epoch [15/25], Step [300/508], Loss: 0.8131\n",
      "Epoch [15/25], Step [400/508], Loss: 1.0983\n",
      "Epoch [15/25], Step [500/508], Loss: 0.7293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 60.37456875308033 %\n",
      "[[122   6  91   3   5  62]\n",
      " [ 12 174  14  12   4   6]\n",
      " [ 66   7 484  26 212  41]\n",
      " [  1   7  25 262  20   2]\n",
      " [  5   1  71  11  90   0]\n",
      " [ 47   6  32   3   6  93]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Step [100/508], Loss: 0.5527\n",
      "Epoch [16/25], Step [200/508], Loss: 1.1898\n",
      "Epoch [16/25], Step [300/508], Loss: 0.5377\n",
      "Epoch [16/25], Step [400/508], Loss: 0.6982\n",
      "Epoch [16/25], Step [500/508], Loss: 0.6071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 62.24741251848201 %\n",
      "[[ 90   2  50   0   5  43]\n",
      " [  6 174   9   5   1   4]\n",
      " [116  14 593  37 248  79]\n",
      " [  1   8  18 267  17   3]\n",
      " [  2   1  32   8  64   0]\n",
      " [ 38   2  15   0   2  75]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Step [100/508], Loss: 0.2821\n",
      "Epoch [17/25], Step [200/508], Loss: 0.9562\n",
      "Epoch [17/25], Step [300/508], Loss: 0.7836\n",
      "Epoch [17/25], Step [400/508], Loss: 0.6032\n",
      "Epoch [17/25], Step [500/508], Loss: 0.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 61.21241991128635 %\n",
      "[[122  12  76   0   9  50]\n",
      " [  5 151   3   2   2   2]\n",
      " [ 79  11 491  20 184  56]\n",
      " [  3  22  41 281  30   9]\n",
      " [  5   1  83  12 110   0]\n",
      " [ 39   4  23   2   2  87]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Step [100/508], Loss: 0.5045\n",
      "Epoch [18/25], Step [200/508], Loss: 0.5139\n",
      "Epoch [18/25], Step [300/508], Loss: 0.4586\n",
      "Epoch [18/25], Step [400/508], Loss: 1.0340\n",
      "Epoch [18/25], Step [500/508], Loss: 0.3557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 60.6209955643174 %\n",
      "[[ 99   2  71   0   8  56]\n",
      " [ 12 170   7   7   2   4]\n",
      " [ 92  10 533  28 215  64]\n",
      " [  3  14  23 258  13   7]\n",
      " [  3   1  61  23  97   0]\n",
      " [ 44   4  22   1   2  73]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Step [100/508], Loss: 0.5472\n",
      "Epoch [19/25], Step [200/508], Loss: 1.1497\n",
      "Epoch [19/25], Step [300/508], Loss: 0.6954\n",
      "Epoch [19/25], Step [400/508], Loss: 0.2894\n",
      "Epoch [19/25], Step [500/508], Loss: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.551010349926074 %\n",
      "[[ 94  17  61   2   8  45]\n",
      " [  6 153   5   5   3   4]\n",
      " [ 97  22 444  39 147  57]\n",
      " [  0   4  17 235   7   1]\n",
      " [  9   1 163  33 169   4]\n",
      " [ 47   4  27   3   3  93]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Step [100/508], Loss: 0.2399\n",
      "Epoch [20/25], Step [200/508], Loss: 0.6856\n",
      "Epoch [20/25], Step [300/508], Loss: 0.5883\n",
      "Epoch [20/25], Step [400/508], Loss: 0.2945\n",
      "Epoch [20/25], Step [500/508], Loss: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.94529324790537 %\n",
      "[[136   6 116   1  28  56]\n",
      " [  7 172  12   7   1   6]\n",
      " [ 57  10 376  16 140  29]\n",
      " [  3   8  27 269  22   9]\n",
      " [  5   2 152  21 142   3]\n",
      " [ 45   3  34   3   4 101]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Step [100/508], Loss: 0.5265\n",
      "Epoch [21/25], Step [200/508], Loss: 0.3711\n",
      "Epoch [21/25], Step [300/508], Loss: 0.2861\n",
      "Epoch [21/25], Step [400/508], Loss: 0.4056\n",
      "Epoch [21/25], Step [500/508], Loss: 0.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.649581074420894 %\n",
      "[[112  13  93   1  11  53]\n",
      " [  8 159   5   6   2   3]\n",
      " [ 71   9 438  26 177  35]\n",
      " [  3  15  32 268  29   6]\n",
      " [  8   1 101  13 109   3]\n",
      " [ 51   4  48   3   9 104]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Step [100/508], Loss: 0.5863\n",
      "Epoch [22/25], Step [200/508], Loss: 0.2693\n",
      "Epoch [22/25], Step [300/508], Loss: 0.3446\n",
      "Epoch [22/25], Step [400/508], Loss: 0.6249\n",
      "Epoch [22/25], Step [500/508], Loss: 0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 58.600295712173484 %\n",
      "[[129   7  92   0  16  54]\n",
      " [  6 162   8   9   1   4]\n",
      " [ 78  12 430  30 163  63]\n",
      " [  1  14  18 248  12   2]\n",
      " [  8   0 142  24 143   4]\n",
      " [ 31   6  27   6   2  77]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Step [100/508], Loss: 0.2862\n",
      "Epoch [23/25], Step [200/508], Loss: 0.2375\n",
      "Epoch [23/25], Step [300/508], Loss: 0.2142\n",
      "Epoch [23/25], Step [400/508], Loss: 0.5695\n",
      "Epoch [23/25], Step [500/508], Loss: 0.2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 59.33957614588467 %\n",
      "[[106   3  79   0   9  39]\n",
      " [  4 168   5   9   3   5]\n",
      " [ 83  15 486  40 206  54]\n",
      " [  3  10   9 243  12   3]\n",
      " [  8   1  98  18 102   4]\n",
      " [ 49   4  40   7   5  99]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Step [100/508], Loss: 0.1058\n",
      "Epoch [24/25], Step [200/508], Loss: 0.1713\n",
      "Epoch [24/25], Step [300/508], Loss: 0.2646\n",
      "Epoch [24/25], Step [400/508], Loss: 0.1421\n",
      "Epoch [24/25], Step [500/508], Loss: 0.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 57.91030064070971 %\n",
      "[[ 96   9  66   3   7  50]\n",
      " [ 10 166  14   9   5   7]\n",
      " [107  16 479  37 200  55]\n",
      " [  2   5  24 249  15   6]\n",
      " [  4   0 109  10 103   4]\n",
      " [ 34   5  25   9   7  82]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Step [100/508], Loss: 0.0658\n",
      "Epoch [25/25], Step [200/508], Loss: 0.0556\n",
      "Epoch [25/25], Step [300/508], Loss: 0.5709\n",
      "Epoch [25/25], Step [400/508], Loss: 0.0634\n",
      "Epoch [25/25], Step [500/508], Loss: 0.0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 57.71315919172006 %\n",
      "[[120   8 108   0  16  58]\n",
      " [  6 152   6   4   2   3]\n",
      " [ 84  23 444  33 177  57]\n",
      " [  2  12  29 264  25   4]\n",
      " [  9   1 107  12 110   1]\n",
      " [ 32   5  23   4   7  81]]\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 25\n",
    "loss_tracker = []\n",
    "valid_cfn_matrix = []\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, (mels_images, tempo_images, labels) in enumerate(train_loader):\n",
    "\n",
    "        mels_images = mels_images.float()\n",
    "        tempo_images = tempo_images.float()\n",
    "        \n",
    "        mels_images = mels_images.to(device, dtype=torch.float)\n",
    "        tempo_images = tempo_images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model([mels_images, tempo_images])\n",
    "        \n",
    "        loss = criterion(outputs, labels.squeeze())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _x, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (labels.squeeze() == predicted).sum().item()\n",
    "        loss_tracker.append(loss.item())\n",
    "        if (i+1) % 100 == 0:\n",
    "            #print (correct, total)\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "          \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (mels_images, tempo_images, labels) in enumerate(valid_loader):\n",
    "            mels_images = mels_images.float()\n",
    "            tempo_images = tempo_images.float()\n",
    "            mels_images = mels_images.to(device)\n",
    "            tempo_images = tempo_images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model([mels_images, tempo_images])\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (labels.squeeze() == predicted).sum().item()\n",
    "\n",
    "            all_predictions.extend(list(predicted.cpu().numpy()))\n",
    "            all_labels.extend(list(labels.squeeze().cpu().numpy()))\n",
    "\n",
    "        print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "        \n",
    "        import sklearn\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        cf_matrix = sklearn.metrics.confusion_matrix(all_predictions, all_labels)\n",
    "        valid_cfn_matrix.append(cf_matrix)\n",
    "        print (cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test images: 48.74322326269098 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (mels_images, tempo_images, labels) in enumerate(valid_loader):\n",
    "        mels_images = mels_images.float()\n",
    "        tempo_images = tempo_images.float()\n",
    "        \n",
    "        mels_images = mels_images.to(device)\n",
    "        tempo_images = tempo_images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model([mels_images, tempo_images])\n",
    " \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (labels.squeeze() == predicted).sum().item()\n",
    "\n",
    "        all_predictions.extend(list(predicted.cpu().numpy()))\n",
    "        all_labels.extend(list(labels.squeeze().cpu().numpy()))\n",
    "\n",
    "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146  39 158   7  44  72]\n",
      " [  2  80   1   3   1   0]\n",
      " [ 51  21 381  77 159  43]\n",
      " [  4   6  13 176   5   0]\n",
      " [  5   1 119  43 122   5]\n",
      " [ 45  54  45  11   6  84]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print (sklearn.metrics.confusion_matrix(all_predictions, all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Previous run \n",
    "Test Accuracy of the model on the test images: 60.177427304090685 %\n",
    "[[ 94   2  68   0   5  41]\n",
    " [ 13 178  23  20   4  14]\n",
    " [ 83   7 540  36 244  50]\n",
    " [  1   5  21 249  18   0]\n",
    " [  3   0  33   9  61   0]\n",
    " [ 59   9  32   3   5  99]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note --\n",
    "\n",
    "model.eval - acc =48.74%\n",
    "with torch.no_grad(): - acc = 62.25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
