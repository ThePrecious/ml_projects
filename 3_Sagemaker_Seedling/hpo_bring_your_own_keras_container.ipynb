{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hyperparameter Tuning using Your Own Keras/Tensorflow Container - Plant Seedling Classification\n",
    "\n",
    "This notebook shows how to build your own Keras(Tensorflow) container and use SageMaker for training, leveraging hyperparameter tuning. \n",
    "\n",
    "We use VGG19 with Imagenet weights to perform transfer learning using Keras and train a plant seedling classification model\n",
    "\n",
    "This tutorial uses code from https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning/keras_bring_your_own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the notebook instance to support local mode\n",
    "Currently you need to install docker-compose in order to use local mode (i.e., testing the container in the notebook instance without pushing it to ECR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "We will set up a few things before starting the workflow. \n",
    "\n",
    "1. get the execution role which will be passed to sagemaker for accessing your resources such as s3 bucket\n",
    "2. specify the s3 bucket and prefix where training data set and model artifacts are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "smclient = boto3.client('sagemaker')\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()  # s3 bucket name, must be in the same region as the one specified above\n",
    "prefix = 'sagemaker/hpo-keras-seedling'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.upload_data(path='npX_keras.pkl', bucket=bucket, key_prefix='data/hpo-keras-seedling/train')\n",
    "sagemaker_session.upload_data(path='oh_npY.pkl', bucket=bucket, key_prefix='data/hpo-keras-seedling/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-01 04:16:52  317.3 MiB data/hpo-keras-seedling/train/npX_keras.pkl\r\n",
      "2018-08-01 04:16:55  876.9 KiB data/hpo-keras-seedling/train/oh_npY.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://<bucket>/data/hpo-keras-seedling/train --recursive --human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete source code\n",
    "- [trainer/start.py](trainer/start.py): Keras model\n",
    "- [trainer/environment.py](trainer/environment.py): Contain information about the SageMaker environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the image\n",
    "We will build the docker image using the Tensorflow versions on dockerhub. The full list of Tensorflow versions can be found at https://hub.docker.com/r/tensorflow/tensorflow/tags/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building image:127230316473.dkr.ecr.us-west-2.amazonaws.com/test:tensorflow-latest-gpu\n"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "import subprocess\n",
    "\n",
    "def get_image_name(ecr_repository, tensorflow_version_tag):\n",
    "    return '%s:tensorflow-%s' % (ecr_repository, tensorflow_version_tag)\n",
    "\n",
    "def build_image(name, version):\n",
    "    cmd = 'docker build -t %s --build-arg VERSION=%s -f Dockerfile .' % (name, version)\n",
    "    subprocess.check_call(shlex.split(cmd))\n",
    "\n",
    "#version tag can be found at https://hub.docker.com/r/tensorflow/tensorflow/tags/ \n",
    "#e.g., latest cpu version is 'latest', while latest gpu version is 'latest-gpu'\n",
    "tensorflow_version_tag = 'latest-gpu'   \n",
    "\n",
    "account = boto3.client('sts').get_caller_identity()['Account']\n",
    "    \n",
    "ecr_repository=\"%s.dkr.ecr.%s.amazonaws.com/test\" %(account,region) # your ECR repository, which you should have been created before running the notebook\n",
    "\n",
    "image_name = get_image_name(ecr_repository, tensorflow_version_tag)\n",
    "\n",
    "print('building image:'+image_name)\n",
    "build_image(image_name, tensorflow_version_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels\n",
    "train_data_location = 's3://sagemaker-us-west-2-127230316473/data/hpo-keras-seedling/train'\n",
    "channels = {'train': train_data_location}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECR Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD IAM role allowing access to ECR (attach 1 policies) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## refer to tutorial link below to grant SageMaker IAM access to ECR:\n",
    "#https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our own ECR repository if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws ecr create-repository --repository-name test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing the container to ECR\n",
    "Now that we've tested the container locally and it works fine, we can move on to run the hyperparmeter tuning. Before kicking off the tuning job, you need to push the docker image to ECR first. The ECR repository has been set up in the beginning of the sample notebook, please make sure you have input your ECR repository information there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing image:127230316473.dkr.ecr.us-west-2.amazonaws.com/test:tensorflow-latest-gpu\n"
     ]
    }
   ],
   "source": [
    "def push_image(name):\n",
    "    cmd = 'aws ecr get-login --no-include-email --region '+region\n",
    "    login = subprocess.check_output(shlex.split(cmd)).strip()\n",
    "\n",
    "    subprocess.check_call(shlex.split(login.decode()))\n",
    "\n",
    "    cmd = 'docker push %s' % name\n",
    "    subprocess.check_call(shlex.split(cmd))\n",
    "\n",
    "print (\"pushing image:\"+image_name)\n",
    "push_image(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify hyperparameter tuning job configuration\n",
    "*Note, with the default setting below, the hyperparameter tuning job can take 20~30 minutes to complete. You can customize the code in order to get better result, such as increasing the total number of training jobs, epochs, etc., with the understanding that the tuning time will be increased accordingly as well.*\n",
    "\n",
    "Now you configure the tuning job by defining a JSON object that you pass as the value of the TuningJobConfig parameter to the create_tuning_job call. In this JSON object, you specify:\n",
    "* The ranges of hyperparameters you want to tune\n",
    "* The limits of the resource the tuning job can consume \n",
    "* The objective metric for the tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seedling-keras-HPO-03-01-12-17\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from time import gmtime, strftime\n",
    "\n",
    "tuning_job_name = 'seedling-keras-HPO-' + strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "print(tuning_job_name)\n",
    "\n",
    "tuning_job_config = {\n",
    "    \"ParameterRanges\": {\n",
    "      \"CategoricalParameterRanges\": [],\n",
    "      \"ContinuousParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"0.0003\",\n",
    "          \"MinValue\": \"0.0001\",\n",
    "          \"Name\": \"learning_rate\",          \n",
    "        }\n",
    "      ],\n",
    "      \"IntegerParameterRanges\": [\n",
    "        {\n",
    "          \"MaxValue\": \"300\",\n",
    "          \"MinValue\": \"150\",\n",
    "          \"Name\": \"epochs\",          \n",
    "        },\n",
    "        {\n",
    "          \"MaxValue\": \"36\",\n",
    "          \"MinValue\": \"24\",\n",
    "          \"Name\": \"batch_size\",          \n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"ResourceLimits\": {\n",
    "      \"MaxNumberOfTrainingJobs\": 8,\n",
    "      \"MaxParallelTrainingJobs\": 1\n",
    "    },\n",
    "    \"Strategy\": \"Bayesian\",\n",
    "    \"HyperParameterTuningJobObjective\": {\n",
    "      \"MetricName\": \"acc\",\n",
    "      \"Type\": \"Maximize\"\n",
    "    }\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify training job configuration\n",
    "Now you configure the training jobs the tuning job launches by defining a JSON object that you pass as the value of the TrainingJobDefinition parameter to the create_tuning_job call.\n",
    "In this JSON object, you specify:\n",
    "* Metrics that the training jobs emit\n",
    "* The container image for the algorithm to train\n",
    "* The input configuration for your training and test data\n",
    "* Configuration for the output of the algorithm\n",
    "* The values of any algorithm hyperparameters that are not tuned in the tuning job\n",
    "* The type of instance to use for the training jobs\n",
    "* The stopping condition for the training jobs\n",
    "\n",
    "This example defines one metric that Tensorflow container emits: loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image = image_name\n",
    "\n",
    "\n",
    "training_job_definition = {\n",
    "    \"AlgorithmSpecification\": {\n",
    "      \"MetricDefinitions\": [\n",
    "        {\n",
    "          \"Name\": \"acc\",\n",
    "          \"Regex\": \"accuracy: ([0-9\\\\.]+)\"\n",
    "        }\n",
    "      ],\n",
    "      \"TrainingImage\": training_image,\n",
    "      \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": channels['train'],\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"test\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": channels['train'],\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },            \n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\"            \n",
    "        }\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\n",
    "      \"S3OutputPath\": \"s3://{}/{}/output\".format(bucket,prefix)\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "      \"InstanceCount\": 1,\n",
    "      \"InstanceType\": \"ml.p2.xlarge\",\n",
    "      \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"StaticHyperParameters\": {\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "      \"MaxRuntimeInSeconds\": 43200\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and launch a hyperparameter tuning job\n",
    "Now you can launch a hyperparameter tuning job by calling create_tuning_job API. Pass the name and JSON objects you created in previous steps as the values of the parameters. After the tuning job is created, you should be able to describe the tuning job to see its progress in the next step, and you can go to SageMaker console->Jobs to check out the progress of each training job that has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-west-2:127230316473:hyper-parameter-tuning-job/seedling-keras-hpo-03-01-12-17',\n",
       " 'ResponseMetadata': {'RequestId': 'c4435e2b-75d9-4954-ad13-e56cef30c760',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c4435e2b-75d9-4954-ad13-e56cef30c760',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '131',\n",
       "   'date': 'Fri, 03 Aug 2018 01:12:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.create_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name,\n",
    "                                               HyperParameterTuningJobConfig = tuning_job_config,\n",
    "                                               TrainingJobDefinition = training_job_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just run a quick check of the hyperparameter tuning jobs status to make sure it started successfully and is `InProgress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = tuning_job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.832214765100671 * 298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.767361</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>2018-08-03 04:36:00+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-008-c744b7c3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 04:11:37+00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.827559</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>2018-08-03 04:07:43+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-007-0554dfc8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 03:43:06+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807978</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>2018-08-03 03:37:20+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-006-f74e33fe</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 03:12:34+00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.837662</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>2018-08-03 03:09:22+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-005-c7e1ad7c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 02:42:56+00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.816444</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>2018-08-03 02:38:43+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-004-dddd668c</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 02:13:37+00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.616898</td>\n",
       "      <td>879.0</td>\n",
       "      <td>2018-08-03 02:11:41+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-003-ac360a4f</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 01:57:02+00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.653935</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>2018-08-03 01:52:56+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-002-37c6d555</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 01:35:18+00:00</td>\n",
       "      <td>36.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.635158</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>2018-08-03 01:33:01+00:00</td>\n",
       "      <td>seedling-keras-HPO-03-01-12-17-001-ad5afbb8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>2018-08-03 01:14:48+00:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FinalObjectiveValue  TrainingElapsedTimeSeconds           TrainingEndTime  \\\n",
       "0             0.767361                      1463.0 2018-08-03 04:36:00+00:00   \n",
       "1             0.827559                      1477.0 2018-08-03 04:07:43+00:00   \n",
       "2             0.807978                      1486.0 2018-08-03 03:37:20+00:00   \n",
       "3             0.837662                      1586.0 2018-08-03 03:09:22+00:00   \n",
       "4             0.816444                      1506.0 2018-08-03 02:38:43+00:00   \n",
       "5             0.616898                       879.0 2018-08-03 02:11:41+00:00   \n",
       "6             0.653935                      1058.0 2018-08-03 01:52:56+00:00   \n",
       "7             0.635158                      1093.0 2018-08-03 01:33:01+00:00   \n",
       "\n",
       "                               TrainingJobName TrainingJobStatus  \\\n",
       "0  seedling-keras-HPO-03-01-12-17-008-c744b7c3         Completed   \n",
       "1  seedling-keras-HPO-03-01-12-17-007-0554dfc8         Completed   \n",
       "2  seedling-keras-HPO-03-01-12-17-006-f74e33fe         Completed   \n",
       "3  seedling-keras-HPO-03-01-12-17-005-c7e1ad7c         Completed   \n",
       "4  seedling-keras-HPO-03-01-12-17-004-dddd668c         Completed   \n",
       "5  seedling-keras-HPO-03-01-12-17-003-ac360a4f         Completed   \n",
       "6  seedling-keras-HPO-03-01-12-17-002-37c6d555         Completed   \n",
       "7  seedling-keras-HPO-03-01-12-17-001-ad5afbb8         Completed   \n",
       "\n",
       "          TrainingStartTime  batch_size  epochs  learning_rate  \n",
       "0 2018-08-03 04:11:37+00:00        36.0   298.0       0.000300  \n",
       "1 2018-08-03 03:43:06+00:00        24.0   288.0       0.000299  \n",
       "2 2018-08-03 03:12:34+00:00        28.0   300.0       0.000271  \n",
       "3 2018-08-03 02:42:56+00:00        28.0   300.0       0.000296  \n",
       "4 2018-08-03 02:13:37+00:00        29.0   296.0       0.000280  \n",
       "5 2018-08-03 01:57:02+00:00        36.0   170.0       0.000172  \n",
       "6 2018-08-03 01:35:18+00:00        36.0   201.0       0.000221  \n",
       "7 2018-08-03 01:14:48+00:00        25.0   196.0       0.000119  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tuner = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "full_df = tuner.dataframe()\n",
    "full_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
